[{"content":"Smart Caps Lock: Remap to Control AND Escape (Linux, Mac, Windows)  Send Escape if you tap Caps Lock alone. Send Control if you press Caps Lock with another key. send caps lock if you press both shift keys together  For vim , emacs and normal day typing\nGNU/Linux Step 1. Install XCAPE Install XCAPE (xcape). (Linux utility to configure modifier keys to act as other keys when pressed and released on their own.)\nUbuntu:\n1  sudo apt-get install xcape   Step 2. Run the command 1 2 3 4 5  # make CapsLock behave like Ctrl: setxkbmap -option ctrl:nocaps # make short-pressed Ctrl behave like Escape: xcape -e \u0026#39;Control_L=Escape\u0026#39;   The effect should apply immediately.\nStep 3. Autostart Append code from Step 2 to file ~/.xprofile to run the command when X starts.\nmacOS  Download and install Karabiner-Elements, a powerful and stable keyboard customizer. Open Karabiner-Elements, select Complex Modifications tab, and click Add rule at the bottom. Find Post escape if caps is pressed alone, left_ctrl otherwise and click on enable.  The effect should apply immediately.\nWindows Option 1:  Download and install AutoHotKey. Use the script CapsLockCtrlEscape.ahk.  This was made possible with a third party software called AutoHotkey described as the Altimate automation script for windows systems.\nI choose to use these program since i plan to do some automations with it in the future.\nI admit i did not write the script for this program myself by i sourced out from github.\nThis script came with something additional that i loved. I did not lose the caps lock fuctionality as in my linux distro. Pressing the two shift keys together activates thes caps lock.\n","description":"","id":2,"section":"posts","tags":["productivity",""],"title":"Mappingcapstoctrlandescape","uri":"https://eduuh.github.io/posts/mappingcapstoctrlandescape/"},{"content":"A simpler way to manage your dotfiles Hello am edd I have been having trouble with configuration since i started using docker for my development. For consistecy and time saving , i decided it would be great to manage my dotfiles using git and github and when creating new enviroments.\nI wrote the solution in this post, for easy reference if i need to in the future.\nWhat are dotfile Dotfile are file in the linux system that starts with a period. They are mainly used to store configuration files for the User instance for various applications. For me the dotfiles that i would love to manage are as follow.\nYes setup.sh this is a custom setup script that i maintain to initially setup a new installation with all the setting and softwares i need in my system. Could be used to\n setup the configuration files managed by the git repository. Setup my keyboard mapping to the way a need them to be .  The keyboard mapping i love most, and spend alot of time setting it up is Remapping caps lock to act as a control key when pressed together with other character, and behave as Escape when pressed alone.\nI would love to automate the process , so that i don\u0026rsquo;t even think about it. Like most folks, I use git to manage my \u0026lsquo;dotfiles. This lets me have a versioned backup for my configurations, and if something breaks (and it often does) I can revert to a working configuration fairly easily. I came across a post of how to manage the dotfiles without the need for anysymlinking.\nThe key idea is really simple: make $HOME the git work-tree. The normal way of doing this would be to do a git init in you $HOME, but that would totally mess up git commands if you have other repositories in your $HOME (also, you probably don't want your entire $HOME in a git repository.\nWe will create a dummy folder and initialize a bare repository.Essentially a git repo with no working directory in there. All git commands will be run with our dummy as the git directory, but $HOME as the work directory.\nGit bare Repository. A git repository is a repository that is created without a Working Tree but just the contents of what is typically in the .git directory.\nWhy this setup?\nA bare repository is typically used as a Remote Repository that is sharing a repository amoung several different people. You don\u0026rsquo;t do work right inside the remote repository so there\u0026rsquo;s no working Tree.\nManage your dotfiles with bare repository (First Time). Requirements.  Git installed. Create a remote dotfile repository on github or any other service.  Setting this method up the first time is really easy. First, let\u0026rsquo;s create our bare repository. I chose to name my placeholder .dotfiles. Ofcourse you can use any name.\n1 2  mkdir $HOME/.dotfiles git init --bare $HOME/.dotfiles   Now for fun part. We will make an alias for running git commands in our .dotfiles repository. I\u0026rsquo;m calling my alias dotfiles: .Make sure you reference the right dotfiles folder which are anywhere within your $HOME folder.\nThis alias references the git binary and also indicates the Home folder as your working tree.\n1  alias dotfiles=\u0026#39;/usr/bin/git --git-dir=$HOME/.dotfiles/ --work-tree=$HOME\u0026#39;   Add this alias to your .bashrc. From now any git operation you would like to do in the .dotfiles repository can be done by the dotfiles alias. The cool thing is that you can run dotfiles from anywhere.\nSource the url of the remote dotfiles folder and use it to configure the origin.\nLets add a remote and also set status now to show untracked files since there will be a long list of Untracked files. You will only track a few of the files.\n1 2  dotfiles config --local status.showUntrackedFiles no dotfiles remote add origin https://github.com/eduuh/dotfiles.git   Adding the conf to Source control. Note: Avoid using dotfiles add . since you don\u0026rsquo;t want to and your home folder to your dotfile repository.\nexample:\n1 2  dotfiles add .bashrc dotfiles commit -m \u0026#34;added bash configuration file to source control\u0026#34;   Note that we create an alias for the current session. In order to make the alias to be available we need to add the line to the configuration file of the terminal that you use. For me I added the line in my .zshrc.\nSetting Up a New Machine With existing Configuration. Method 1 Assumtion is that you are using the above described method to store your dotfiles.Make a backup folder first and backup the default configuration available for your application. But in most cases you man not have them.\nSetting this method up the first time is really easy. First, let\u0026rsquo;s create our bare repository. I chose to name my placeholder .dotfiles. Ofcourse you can use any name.\n1 2  mkdir $HOME/.dotfiles git init --bare $HOME/.dotfiles   Set up the alias for the current session using the command.\n1  alias dotfiles=\u0026#39;/usr/bin/git --git-dir=$HOME/.dotfiles/ --work-tree=$HOME\u0026#39;   Set up the remote github repository.\n1 2  dotfiles config --local status.showUntrackedFiles no dotfiles remote add origin https://github.com/eduuh/dotfiles.git   Pull in the changes form your remote repository.\n1 2  dotfiles pull origin master dotfiles reset --hard HEAD # ovewrites the Home Directory   Method 2 Assuming that your configuration are in github. To set up your computer using your configs is simple.\nTo set up a new machine to use your version controlled config files, all you need to do is to clone the repository on your new machine telling git that it is a bare repository:\nPerform the above steps.\n1  git clone --separate-git-dir=$HOME/.dotfiles https://github.com/eduuh/dotfiles.git   However, some programs create default config files, so this might fail if git finds an existing config file in your $HOME. In that case a simple sol is to clone to a temporayry directory and then delete it once you are done:\n1  git clone --separate-git-dir=$HOME/.dotfiles https://github.com/eduuh/dotfiles.git   So this might fail if git finds an existing config file in your $HOME. In that case, a simple solution is to clone to a temporary directory , and then delete it once you are done:\n1 2 3 4  $ git clone --separate-git-dir=$HOME/.dotfiles https://github.com/eduuh/dotfiles.git --recursive --verbose --exclude \u0026#39;.git\u0026#39; tmpdotfiles/ $HOME/ rm -r tmpdotfiles   The last step is to add the dotfile alias in your bashrc or zshrc according to the shell you are using.\n1  alias dotfiles=\u0026#39;/usr/bin/git --git-dir=$HOME/.dotfiles/ --work-tree=$HOME\u0026#39;c   Using the dotfiles alias For the Dotfiles repository, Your will use dotfiles instead of git. Use it as you normally use git commands.\nExample of some Commands:\nA commit command.\n1 2 3 4 5  dotfiles commit -m \u0026#34;zshrc =\u0026gt; zsh oh my god configuration files \u0026#34; [master 64a553b] zshrc =\u0026gt; zsh oh my god configuration files 1 file changed, 91 insertions(+) create mode 100644 .zshrc   A push action.\n1 2 3 4 5 6 7 8 9  dotfiles push Enumerating objects: 4, done. Counting objects: 100% (4/4), done. Delta compression using up to 4 threads Compressing objects: 100% (3/3), done. Writing objects: 100% (3/3), 1.45 KiB | 1.45 MiB/s, done. Total 3 (delta 0), reused 0 (delta 0) To https://github.com/eduuh/dotfiles.git 7d507e7..64a553b master -\u0026gt; master   The repository will be downloaded but there might exist some configuration files in your home directory to make sure you are using the right configuration file use git checkout to actually copy the copy in your repository to the working directory.\n1  dotfiles checkout $HOME/.bashrc   Or easy is to checkout to the latest commit. Remember Head points to the latest commit use that.\n1 2  dotfiles reset --hard HEAD HEAD is now at 64a553b zshrc =\u0026gt; zsh oh my god configuration files   64a553b at this time this is my latest commit.\nDo not worry git reset --hard copied files available in your repository to both the staging area and the working area . It should not mess with your untracted files which i believe they are many, since this is a repository monitoring the $HOME directory.\nThere you go. No symlink mess.\nMy dotfiles are here for reference.\n","description":"Efficient way to manage configuration files in a linux system.","id":3,"section":"posts","tags":["productivity",""],"title":"Managing Dotfiles Like a Pro","uri":"https://eduuh.github.io/posts/mngdotfilelikeapro/"},{"content":"The Linux Command Line Before you can dive into working with the linux command line and shells, you should first understand what linux is, where it came from and how it works.\n What is Linux  If you\u0026rsquo;ve never worked with Linux before, you may be confused about so many different versions are available.\nFirst, Four main part makes up a linux system:\n The Linux kernel The Gnu Utilities A graphical desktop enviroment Application software.  Each of these parts has a specific job in the linux system. No part is very useful by itself.\nLooking into the Linux Kernel. The core of the Linux system is the kernel. The kernel:\n controls all the hardware and sofware on the computer system\n(allocating hardware when necessary and executing software when required.)  If you\u0026rsquo;ve been following the Linux world at all, no doubt you\u0026rsquo;ve heard the name Linus Torvalds. Linus is the person responsible for creating the first linux kernel softwae whe he was a student at university of Helsinki. He intended it to be a copy of the Unix system, at the time a popular operating system used at many universities.\nAfter developing the linux kernel, linus released it to the internet community and solicited suggestions for improving it. This simple pros started a revolution in the world of computer operating sytems.Soon Linux was receiving suggestions from students as well as professional programmers from around the world. Allowing anyone to change programming code in the kernel would result in complete chaos.\nTo simplify things, linus acted as a central point for all improvement suggestions. It was ultimately Linux\u0026rsquo;s decision whether or not to incorporate suggested code in the kernel.\nThis same concept is still in place with the linux kernel code, except that instead of just linux controlling the kernel code, a team of developers has taken on the task.\nThe kernel is primarily responsible for four main functions:\n System memory management Software Program management Hardware management Filesystem management  System Memory Management Not only does the kernel manages the physical memory available on the server, but it can also create and manage virtual memory (memory that does not actually exist).\nIt does this by using space on the hard disk, called the swap space. The kernel swaps the contents of virtual memory location back and forth from the swap space to the actual physical memory. This allows the system to think there is more memory available than what physically exists.\nThe memory locations are grouped into blocks called pages. The kernel locates each page of memory either in the physical memory or the swap space. The kernel then maintains memory page that indicates which pages are in physical memory and which pages are swapped out of disk.\nSoftware Program Management The linux operating system calls a running program a process. A process can run in the foreground, displaying output on a display, or it can run in the background.\nThe kernel creates the first process, called the init process, to start all other processes on the system. When the kernel starts, it loads the init process into virtual memory. As the kernel starts each additional process, it gives it a unique area in virtual memory to store the data and code that the process uses.\nSome linux implementations contain a table of processes to start automatically on bootup. On linux systems, this table is usually located in the special file /etc/inittabs.\nOther systems (such as the popular Ubuntu linux distribution) Utilze the /etc/init.d* folder, which contains scripts for starting and stopping individual application at boot time. The Scrips are started via entries under the **/etc/rx.d** folders where X is a run level.\nHardware Management Any device that the Linux system must communicate with needs driver code inserted inside the kernel code. The drive code allows the kernel to pass data back and forth to the device, acting as a midlle man between application and the hardware. Two methods are used for inserting device driver code in the Linux kernel.\n Driver compiled in the kernel. Driver modules added to the kernel.  The only way to insert device driver code was to recompile the kernel. Each time you added a new device to the system, you had to recompile the kernel code. This process became even more inefficient as Linux kernel supported more hardware. Fortunately Linux developers devised a better method to insert driver code into the running kernel.\nProgrammers developed the concept of kernel modules to allow you to insert driver code into a running kernel without having to recompile the kernel. A kernel module could be removed from the kernel when the device was finished being used.\nThe linux system identifies hardware devices as special files, called device files. There are three classification of device files:\n Character Block Network.  Filesystem management The linux kernel can support different types of filesystems to read and write data to and from hard drives. Besides having over a dozen filesystems to read and write data to and from hard drive. Besides having over a dozen filesystems on its own.\nThe GNU utilities The **Gnu Organization (GNU stands for GNU\u0026rsquo;s not Unix) developed a complete set of unix utilities but had no kernel system to run them on. These utilities were developed under a software pilosophy called open source software (OSS).\nThe core Gnu Utilities The Gnu coreutils package consists of three parts:\n Utilities for handling files Utilities for manipulating text Uitlities for managing process.  Basic bash shell commands. The default shell used in many Linux distribution is the GNU bash shell.\nStarting the Shell The GNU bash shell is a program that provides interactive access to the linux system. It runs as a regular program and is normally started whenever a user logs in to a terminal.\nThe etc/passwd file contains a list of all the system user accounts, along with some basic configuration information about each user. Here is an entry\nedd❌1000:1001:edd:/home/edd:/usr/bin/bash\nEach entry has seven data fields, with fields separated by colons. The system uses the data in these fields to assign specific features for the user.\nThe above line means.\nedd log in into linux system and bash program is automatically started.\nThere are two methods of login into a linux box.\n Virtual console terminal. requires a cli prompt Graphical login. requires a graphical emulator.  Using the Shell Prompt. When you log in to a linux virtula console. you get access to the shell cli prompt . The prompt is your gateway to the shell. The place you input commands.\nThe default prompt symbol is a dollar sign ($)\nDifferent distribution uses different format of prompt. Examples\n Ubuntu looks like  edwin@server:~$   CentOs Linux or Manjano  [edwin@server:~$]    The prompt is meant to provide useful information.\n edwin -\u0026gt; Current user Id server -\u0026gt; name of the system  Note that the promp is not static. It could be changed to suit your need.\nInteracting with the bash Manual The man command provides access to the manual pages stored on the linux system. Entering the command man followed by another command provids that utility\u0026rsquo;s manual entry. Try\n1  $ man xterm   When you use the man command to view a command\u0026rsquo;s manual pages, they ared displayed with something called a pager.\nA pager is a utility that allows you to page through displayed text. Thus, you can page through the man pages by pressing the spacebar, or can go line by line using the enter key. you could olso use arrow keys\nWhen you finish with the man pages, press the q key to quit. when you quit you are taken back to the prompt.\nThere are also the information pages called info pages.\nNavigating the Filesystem When you log into the system and reach the command line prompt, you are in your home directory.\nlooking at the Linux Filesytem. If you\u0026rsquo;re new to the linux sytem,you may be confused by how it refences files and directories, especially if you\u0026rsquo;re used to the way microsoft windows system does.\nLinux stores files within a single directory structure calle a virtual directory. The virtual directory contains files paths from all the storage devices installed on the computer, merged into a single directory structure.\nThe linux virtual directory structure contains a single base directory, called the root.Directories and files beneath the root directory are listed based on the directory path used to get to them.\nIn linux you will see files paths similar to the following\n/home/edd/Documents/test.md\nNotice the path does not provide the drive the file is stored on.\nLinux virtual directory is how it incorporate each storage device. The first hard drive installed in a linux system is called the root drive. The root drive contains the virtual directory core. Everythings else builds from there.\nOn the root drive, Linux can use a special directory as mount points. Mount points are directories in the virtual directory where you can assign additional storage devices. linux cause files and directory to appear within these mount opind directories.\nCommon Linux Directory Names    Directory Usage     / root of the virtual directory , no file placed   /bin binary directory,where many GNU user-leve utilities   /boot boot directory, where boot files are stored   /dev device directory,where linux creates user directory   /etc system confiuguration files directory   /home home directory, where linux creates user directory   /lib Libray directory, where system and application libray files are stored   /media media directory, a common place for mount points for removable media   /mnt mount directory, another common place for mount points used for removable media   /opt optional directory, often used to store third-party software packages and data files   /proc process directory, where current hardware and process infromation is stored   /root root home directory   /sbin system binary directory, where many GNU admin-level utilitise   /run run directory, runtime data is held during system operation   /srv Serviced directory, local services store files   /sys System directory, where system hardware information files are stored   /var Variable directory, for files that change frequently, i.x log    Common linux directory are based on Filesystem Hierarchy Standard(FHS). You can move around the virtual directory using a graphical interface. To move around the virtual directory from a cli prompt.\nTraversing directory Use the directory command (cd) to move your shell session to another directory in the linux filesystem.\nThe cd command may take a single parameter, destination. The destination parameter can be expressed using twi different methods.\nUsing absolute directory references You can reference a directory name within the virtual directory system using an absolute directory reference. .\nAn absolute path reference always begins with a forwa slash (/) indicating the virtual directory system\u0026rsquo;s root.\n1  /usr/bin   With the absolute directory reference there\u0026rsquo;s no doubt as to exactly where you want to go. To move to a specific location in the Filesystem usind the absolute directory reference, you just specify the full pathname in the cd command.\n1  cd /use/bin # move to the directory   Prompt originalyy had a tilde (~) in it. After the change to a new directory occurred, the tilde was replaced by /usr/bin..\nIf your prompt has not been configured to show the shell session\u0026rsquo;s current absolute directory location, then you can display the location via a shell command. The pwd command display the shell session\u0026rsquo;s current directory location.\nedwin@server /usr/bin/$ pwd /usr/bin  You can move to any leve within the entire Linux virtual directory structure from any level usind the absolut refence:\nedwin@server: /usr/bin/$ cd /var/log  note: think of absolute as a full path.\nusing Relative directory references Relative directory reference allow you to specify a destination directory reference relative to your current location. A Relative directory reference doest start with a folowrd slash.\nRelative directory reference starts with either a directory name (if you\u0026rsquo;re traversing to a directory under your current directory) or a special character.\nedd@edd:~/Documents$ ls edd@edd:~/Documents$ cd ~/Desktop  You can use a relative directory reference with the cd command is any directory containg subdirectoroies. You can also use a special character to indcate a relative directory location.\nThe two special character used for relative directory reference*.\n The single dot (.) to represent the current directory The double dot (..) to represent the parent directory  You can use the single dot but it doesn\u0026rsquo;t make sense to use it with the cd command. The double dot character is extremely handy when trying to traverse a directory and need to go to your Downloads directory.\n edwin@server: ~/Documents$ pwd /home/edd/Documents edwin@server: ~/Documents$ cd ../Downloads edwin@server: ~/Downloads cd ../Downloads   Use absolute path if it makes sense to use.  Listing Files and Diretory. To list the content of a directory we use the ls command.\nDisplaying a basic Listing The ls command at its most basic form displays the files and directory located in your current directory.\n$ ls aur Downloads package-lock.json README.md Videos bunnyflydotfiles_colemak input Pictures snap yay Desktop Music Public Templates Documents node_modules readme.md text.txt  If you don\u0026rsquo;t have a color terminal emulator, you can use the -F parameter with the ls command to the easily distinguish files from directory. Using the -F parameter produces the following ouput.\n$ ls -F aur/ Downloads/ package-lock.json README.md Videos/ bunnyflydotfiles_colemak/ input/ Pictures/ snap/ yay/ Desktop/ Music/ Public/ Templates/ Documents/ node_modules/ readme.md text.txt  The -F parameter flags the directoies with a forward slash (/) to help identify them in the listing.\nThe basic ls command can be somewhat misleading. It shows the files and directory contained in the current directory. Linux often uses hidden files to store configuration information.\nTo display hidden files along with normal files and directories, use the -a parameter. Here is an example of using the -a parameter with the ls command.\n$ ls -a . .dotfiles package-lock.json .viminfo .. .dotnet Pictures .vscode-oss aur Downloads .pki .Xauthority .bash_history .gitconfig .profile .Xclients  All the files beginning with a period, hidden files.Notice that three files begin with .bash\nThe -R parameter is another options the ls command can use. Called the recursive option, it shows files are contained within subdirectories.\n$ ls -F -R Desktop/ Music/ Public/ Templates/ Documents/ node_modules/ readme.md text.txt ./aur: st-luke-git/ ./aur/st-luke-git: PKGBUILD ./bunnyflydotfiles_colemak: dotfiles/ ./bunnyflydotfiles_colemak/dotfiles  Displaying a Long Listing ls command doesn\u0026rsquo;t produce much information about each files. For listing additional information, another parameter is -l.\n$ ls -l drwxr-xr-x 3 edd edd 4096 Apr 12 00:14 aur drwxr-xr-x 3 edd edd 4096 Apr 13 01:43 bunnyflydotfiles_colemak drwxr-xr-x 3 edd edd 4096 Apr 12 13:15 Desktop drwxr-xr-x 2 edd edd 4096 Apr 11 23:24 Documents  The long listing format lists each file and subdirectory on a single line.\nThe listing shows additional useful information.\n The file type - Such as  directory (d), file (-), linked files (1), Charater device (c) Block device (b)   The file permissions. The number of file hard links. The file owner username. The file primary group name. The file byte size. The last time the file was modified. The filename or directory name.  Filtering listing output To look for information about a file is also possible by using the ls command.\n$ ls -l text.txt -rw-r--r-- 1 edd edd 1 Apr 13 09:45 text.txt  Here we used bracket with two choices of character [tx] t and x . brackets could be used to liss ranges of characters.\n $ ls -l tex[a-z].txt edd@edd:~$ ls -l tex[a-z].txt -rw-r--r-- 1 edd edd 1 Apr 13 09:45 text.txt -rw-r--r-- 1 edd edd 0 Apr 14 18:30 texz.txt  You could also specify what shoud not be included in the search result.\nedd@edd:~$ ls -l tex[!z].txt -rw-r--r-- 1 edd edd 1 Apr 13 09:45 text.txt  The second file texz.txt does not get listed in the result.\nHandling Files The shell provids many file manipulation command on the linux filesystem.\n 1. Creating Files  The touch command is used to create empty files in the system.\nedd@edd:~$ touch test_one edd@edd:~$ ls -l test_one -rw-r--r-- 1 edd edd 0 Apr 14 18:51 test_one  The touch command creates the new file you specify and assign your username as the owner.\nThe touch command can also be used to change the modification time. This is done without changing the content of the file.\nCopying files Copying files and directories from one location in the filesystem to another is a common practise for system administrators. The cp command provides this feature.\nIn its most basic form, the cp command uses two parametes. 1. The source object and the destination object.\n$ cp test_one test_two $ ls -l test_*  If you don\u0026rsquo;t answer y, the file copy does not proceed. You can also copy a file into a pre-existing directory.\n$ cp -i test_one /home/edd/Documents/ edd@edd:~$ ls -la /home/edd/Documents/ total 8 drwxr-xr-x 2 edd edd 4096 Apr 14 20:18 . drwx------ 27 edd edd 4096 Apr 14 20:15 .. -rw-r--r-- 1 edd edd 0 Apr 14 20:18 test_one  The new file is now under the Documents subdirectory, using the same filename as the original.\nYou could easily use relative path directory reference.\n $ cp -i test_one Documents/ $ ls -l Documents  You read about thes special symbols that can be use in relative directory refences. One of them:\n - The single dot (.) represents previous directory. - cp -i /etc/NetworkManager/NetworkManager.conf .  It\u0026rsquo;s hard to see that single dot!. Using the single dot symbols is much easier than typing a full destination object name, when you have long source object names.\nThe -R paramets is powerful cp command option. It allows you to recursively copy the contents of an entire directory in one command.\n $ ls -Fd *txt edd@edd:~$ ls -Fd *txt text.txt texz.txt  You can also used wildcard metacharacters in your cp commands.\n$ cp *scripts mod_scripts/ $ ls -l mod_scripts  This command copied any files that ended with script to mod_scripts.\nUsing tab auto-complete When working at the command line, you can easily mistype a command, directory name, or filename. The longer a directory or filename, the greater the chance that you will mistype it.\nThis is where tab auto-complete can be a lifesaver. Tab auto-complete allows you to start typing a filename or directory name and then press the tab key to have the shell complete it for you:\n$ ls really*  Linking files Linking files is a great option available in the linux filesystem. If you need to maintain two (or more) copies of the same file on the system. Instead of having separate physical placeholder in a directory that points to the real location.\n A symbolic link A hard Link.  A symbolic link is simply a physical file that points to another file somewhere in the virtual directory structure. The two symbolically linked together files do share the same contents.\nTo create a symbolic link to a file, the original file must pre-exist. We can the use the ln command with the -s option to create the symbolic link.\nedd@edd:~$ ln -s text.txt text_link edd@edd:~$ ls -la tex* lrwxrwxrwx 1 edd edd 8 Apr 14 20:49 text_link -\u0026gt; text.txt -rw-r--r-- 1 edd edd 0 Apr 14 18:30 texz.txt  The -\u0026gt; symbol displayed after the symbolic link file\u0026rsquo;s long listing shows that it is symbolically linked to the file data-files.\nAlso note the size of the symbolic link and the actual file.The symbolic link size is 8 bytes while the actual file is 18 bytes. The symbolic link file acts like a pointer to the other file on the virtual directory.\nedd@edd:~$ nvim text.txt edd@edd:~$ ls -la tex* lrwxrwxrwx 1 edd edd 8 Apr 14 20:49 text_link -\u0026gt; text.txt -rw-r--r-- 1 edd edd 18 Apr 14 20:53 text.txt -rw-r--r-- 1 edd edd 0 Apr 14 18:30 texz.txt  Another way to tell these linked files are separate physically files is by viewing their inod numbers. The inode numbers of a file directory is a unique identification number that the kernel assigns to each object in the filesystem.\nedd@edd:~$ ls -i *tex* 3685885 text_link 3686544 text.txt 3686536 texz.txt  The example above have 3685885 and 3686544. They are different files.\nA hard link create a separate virtual file that contains information about the original file and where to locate it. They are physically the same file. When you reference the hard link file.\n [edd@edd ~]$ls -l hard* -rw-r--r-- 1 edd edd 0 Apr 14 21:06 hard_one [edd@edd ~]$ln hard_one hard_link [edd@edd ~]$ls -li hard* 3685885 -rw-r--r-- 2 edd edd 0 Apr 14 21:06 hard_link 3685885 -rw-r--r-- 2 edd edd 0 Apr 14 21:06 hard_one  We used -li command to show both the inode number and long listing for the inode number. This is because they aer physically the same file. The files are exactly the same size.\n Note: you can only create a hard link between files on the same physical medium. To create a link between files under separate physical mediums, you must use a symbolic link.  If you use the cp command to copy a file that\u0026rsquo;s linked to another source file, all you\u0026rsquo;re doind is making another copy of the source file. You can just create a new symbolic link to the original file (no problem).\nRenaming files Renaming files is called moving files. The mv command is available to move both files and directories to another location or a new name:\n[edd@edd ~]$touch fall [edd@edd ~]$ls -li f?ll 3686536 -rw-r--r-- 1 edd edd 0 Apr 14 21:17 fall [edd@edd ~]$mv fall fzll [edd@edd ~]$ls -la f?ll -rw-r--r-- 1 edd edd 0 Apr 14 21:17 fzll  Notice that moving the file changed the name from fall to fzll.The inode number is retained and timestamp value. mv commad affect only a files name.\nYou can also mv to change location.\n$ mv \u0026lt;file\u0026gt; \u0026lt;destination\u0026gt;  you can also used the mv command to move entire directories and their contents:\n[edd@edd ~]$ls -li bunnyfylcolemak total 4 3801890 drwxr-xr-x 5 edd edd 4096 Apr 13 09:48 dotfiles [edd@edd ~]$mv bunnyfylcolemak colemakdotfiles [edd@edd ~]$ls -li colemakdotfiles total 4 3801890 drwxr-xr-x 5 edd edd 4096 Apr 13 09:48 dotfiles  The directories entire content are unchange. The only thing that changes is the name of the directory.\nDeleting files Whether it\u0026rsquo;s to clean up a filesystem or to remove a software package, you always have opportunities to delete files.\nDeleting is called removiing. the command to remove files in the bash shell is rm. The basic form of the rm command is simple.\nNotice that the i command parameter prompts you to make sure that you\u0026rsquo;re serious about removing the file. Thes shell has no recycle bin or trashcan. After you remove a file , it\u0026rsquo;s gone forever.\nManaging Directory Linux hass a few commands that works for both files and directory (such as the cp command) and some that work only for directories. To create a new directory, you need to use a specific command.\nCreating directory Creating a new directory in Linux is easy -Just use the mkdir command:\n$ mkdir new_dir $ ls -ld new_dir  The system create a new directory named new_dir.\n[edd@edd ~]$mkdir new_dir [edd@edd ~]$ls -la new_dir drwxr-xr-x 2 edd edd 4096 Apr 14 23:16 new_dir  You can create directory and subdirectories in \u0026ldquo;bulk\u0026rdquo; if needed.\n $ mkdir new_dir/sub_dir/under_dir [edd@edd ~]$mkdir new_dir/sub_dir/under_dir mkdir: cannot create directory ‘new_dir/sub_dir/under_dir’: No such file or directory  To create several directory and subdirectories at the same time, you need to add the -p parameter.\n$ mkdir -p new_dir/sub_dir/under_dir $ ls -R new_dir  The -p option on the mkdir command makes any missing parent directories as needed. A parent directories is a directory that contains other directories at the next level down the directory tree.\nDeleting directories There are lots of opportunities for bad things to happens when you start deleting directories . The shell tries to protect us from accidental catastrophes as much as possible.\n$ touch new_dir/my_file $ ls -la new_dir $ rmdir new_dir  rmdir command works only for removing empty directories. To fix this, we must remove the file first. Then we can use the rmdir command on the now empty directory:\n$ rm -i new_dir/my_file $ rmdir new_dir  Check the directory structure using the tree command.\nedwin@edwin:~$ tree small_dri/ small_dri/ ├── a_file ├── b_file └── c_file 0 directories, 3 files edwin@edwin:~$ rm -rf small_dri/ edwin@edwin:~$ tree small_dri/ small_dri/ [error opening dir] 0 directories, 0 files  The rm -rf command gives no warnings and no fanfare which is extremely dangerous tool to have, especially if you have superuser privileges.\nViewing Files Content You can use several commands for looking inside files without having to pull out a text editor utility.\nViewing the file type. The file command is a handy little utility to have around. It can peek inside of a file and determine just what king of file it is.\n[edwin@edwin ~]$nvim edd.txt [edwin@edwin ~]$file edd.txt edd.txt: ASCII text  Binary executable programs. The file command determines the platform that the program was complile for and what type of library it requires.\nNow that you know a quick method for viewing a file\u0026rsquo;s type.\nUsing the cat command Used to view the whole files . The cat command is a handy tool for displaying all the data inside a text file.\n [edwin@edwin ~]$cat edd.txt This is test  Monitoring Disk Space Some command line commands can help you manage the media environment on your linux system.\nTo be able to monitor your disk space you need to understand how to mounting media works.\nMost of the linux distribution out there have the ability to automatically mount specific types of removable media. A removable media device is a media that can be easily removed from the pc, such as CD-ROMs and USB memory sticks.\nThe mount command. The command used to mount media is called mount. The mount command displays a list of media devices currently mounted on the system.\n$ mount proc on /proc type proc (rw,nosuid,nodev,noexec,relatime) sys on /sys type sysfs (rw,nosuid,nodev,noexec,relatime) dev on /dev type devtmpfs (rw,nosuid,relatime,size=8017640k,nr_inodes=2004410,mode=755) run on /run type tmpfs (rw,nosuid,nodev,relatime,mode=755) /dev/sdb6 on / type ext4 (rw,noatime,discard)  The mount command provides four pieces of information.\n The device filename of the media. The mount point in the virtual directory where the media is mounted. The filesystem type. The access status of the mount media.  The last entry in the preceding example is a USB memory stick. To manually mount a media device in the virtual directory, you must be logged in as the root user or use the sudo command to run the command as the root user. The following is the basic command for manually mounting a media device.\nmount -t type device directory  The type parameter defines the filesystem type under which the disk was formatted. Linux recognizes lots of different filesystems types. If you share removable media withe your winows PCs, you are most likely to run into thes types:\n vfat : Windows long filesystem ntfs : Windows advanced filesystem used in Windows NT, XP, and Vista. iso9660 : The standard CD-ROM filesystem.  Mount USB memory stick at device /dev/sdb1 at location /media/disk you could use such a command.\n mount -t vfat /dev/sdb1 /media/disk  After a media device is mounted in the virtual directory, the rood user has full access to the device, but access by other users is restricted. You can control who has access to device using directory permissions.\nThe -o options allows you to mount the filesystem with a comma-separated list of additional options. These are popular option to use:\n ro: Mount as read-only rw: mounts as read-write User: Allow an ordinary user to mount the filesystem Check=none: Mount the filesystem without performing an integrity check. loop: Mounts a file.  The Unmount command. To remove a removable media device, you should never just remove it form the system Instead, you should alwayst unmount it first.\nThe command used to unmount devices is unmount (yes, there\u0026rsquo;s no \u0026ldquo;n\u0026rdquo; in the command, which get confusing sometimis). The format of the unmount command is pretty simple.\numount [directory | device ]  The unmount command gives you the choice of defining the media device by either its device location or its mounted directory name. If any Program has a file open on a device the system won\u0026rsquo;t lets you unmount it.\n[dwm@edwin ~]$ sudo umount test umount: /home/dwm/test: target is busy. [dwm@edwin ~]$  Using the df command. Sometimes, you need to see how much disk space is available on an individual device. The df command allows you to easily see what\u0026rsquo;s happening on all the mounted disks.\nFilesystem 1K-blocks Used Available Use% Mounted on dev 8017640 0 8017640 0% /dev run 8027328 1456 8025872 1% /run /dev/sdb6 123443708 16536504 100593580 15% / tmpfs 8027328 0 8027328 0% /dev/shm tmpfs 8027328 0 8027328 0% /sys/fs/cgroup tmpfs 8027328 4 800  The df command shows each mounted filesystem that contains data. As you can see from the mount command, some mounted devices are used for internal system purposes. The command displays the following.\n The device location of the device. How many 1024-byte blockes of data it can hold. How many 1024-byte blocks are available. The amount of used Space as percentage. The mount point where the device is mounted.  A few different command line parameter are available with the df command, most if which you\u0026rsquo;ll never use. One popular parameter is -h, which shows the disk space in human readable form, usually as an M for Megabytes or a G for gitabytes.\n[dwm@edwin ~]$ df -h Filesystem Size Used Avail Use% Mounted on dev 7.7G 0 7.7G 0% /dev run 7.7G 1.5M 7.7G 1% /run /dev/sdb6 118G 16G 96G 15% / tmpfs 7.7G 0 7.7G 0% /dev/shm tmpfs 7.7G 0 7.7G 0% /sys/fs/cgroup tmpfs 7.7G 4.0K 7.7G 1% /tmp tmpfs 1.6G 12K 1.6G 1% /rp  Using the du command With the df command you can easily see when a disk is running out of space. The next problem for the system administrators is to know what to do when that happens.\nthe du command shows the disk usage for a specific directory. this is a quick way to determine if you have any obvious disk hogs on the system. by default, the du command displays all the files directories and subdirectories under the current directories, and it shows how many disk blocks each files or directories takes.\n[dwm@edwin ~/mount/mycodes/blog]$ du 0 ./.git/branches 39 ./.git/hooks 1 ./.git/info 11 ./.git/logs/refs/heads 2 ./.git/logs/refs/remotes/origin | | V V no.of block path of directory The number to the left of each line is the number of disk blocks that each files or directory takes. The listing starts at the bottow of a directory and works its way up through all the files and subdirectories.\nYou can use a few command line parameters with the du command to make things a little more legible:\n-c: Produces a grand total of all the files listed. -h:Prints sizes in human readable form. -s: summarrizes each argument Working with Data Files Handling the information and making it useful can be difficult. Linux system provide several command line tools to help you manage large amount of data. This section covers the basic command that every system administrator as well as any everyday linux user.\nSorting data Thes sort commands does what it says: it sorts data.\nBy default, the sort comman sorts the data linux in a text file using standard sorting rules for the language you specify as the default for the session.\n[dwm@edwin ~]$ sort file1 four one three two By default , sort recognizes everything in a files as characters and performs a character sort. To recognize number we use -n parameter which tells the sort command to recognize numbers as numbers instead of characters and to sort them based on their numerical values.\ncharcter sort\n[dwm@edwin ~]$ sort file2 1 10 2 23 3 3 43 sort with -n prameter. (Numerical sort)\n[dwm@edwin ~]$ sort -n file2 1 2 3 3 10 23 43 45 Another commmon parameter that\u0026rsquo;s used is -M, the month sort. Linux log files usually contain a timestamp at the beginn of the line to indicate whe the event occurred.\nSep 12 04:30:10 testbox smart[2312]: Device: /dev/sda, opened The -k and -t parameter are handy when sorting data that uses fields, such as the /etc/passwd file. Use the -t parameter to specify the field separator character, and ues the -k parameter to specify which field to sort on.\nTo sort the password file based on numerical userid, just do this:\n[dwm@edwin ~]$ sort -t ':' -k 3 -n /etc/passwd root❌0:0::/root:/bin/bash bin❌1:1::/:/usr/bin/nologin daemon❌2:2::/:/usr/bin/nologin mail❌8:12::/var/spool/mail:/usr/bin/nologin ftp❌14:11::/srv/ftp:/usr/bin/nologin rpc❌32:32:Rpcbind Daemon:/var/lib/rpcbind:/usr/bin/nologin Now the data is perfectly sorted on the third field which is the numerical userid value.The -n is great for sorting numeriacal outputs, such as the outputs of the du command:\n[dwm@edwin ~]$ du -sh * | sort -nr 800M Documents 650M visual-studio-code-bin 516K video-200511-1019-38.mkv 328K node_modules 252M test 44K package-lock.json 36K LICENSE 33G VirtualBox VMs Notice that the -r option also sorts the value in desceding order, so you can easily see what files are taking up the most space in your directory.\nSearching for data. Grep Often in a large file, you must look for a specific line of data buried somewhere in the middle of the file. Instead of manually scrolling throught the entire file, you can let the grep command search for you. The command line Format for the grep command is:\ngrep [option] pattern [file] The grep command search either the input or the file you specify for lines that contains character that match thes specified pattern. The outputs from grep is the lines that contains the matching pattern.\nHere are two simple example of using the grep command with the file1 used above command.\n[dwm@edwin ~]$ grep three file1 three The grep command produces the line that contains the matching pattern. If you want to reverse the search (outputs the lines that don\u0026rsquo;t match a pattern) use the -v parameter.\n[dwm@edwin ~]$ grep -v t file1 one four If you need to find the line number where the mapching patterns are found, use the -n parameter.\n[dwm@edwin ~]$ grep -n t file1 2:two 3:three If you need to find the line number where the matching pattern are found use the -n parameter.\nIf you just need to see count of how many lines contains the matching pattern, use the -c parameter:\n[dwm@edwin ~]$ grep -c t file1 2 If you need to specify more than one matching pattern, use the -e parameter to specify each individual pattern:\n[dwm@edwin ~]$ grep -e t -e f file1 two three four The grep command uses basic unix-style regular expression to match patterns. A unix-style regular expression uses special character to define how to look for matching patterns.\nExample of using a regular expression in a grep search.\n// TODO : regular expression does not work on my system\nThe egrep command is an offshoot of grep, which allows you to specify POSIX extended reqular expression, which contains more characters for specifying the matching pattern.\nCompressing Data. No doubt you\u0026rsquo;ve used zip files. Linux contains several files compression utilities. Although this may sount great, it often lead to confusion and chaos when trying to download files.\nLinux file compression utilities\n   Utility File Extension Description     bzip2 .bz2 Uses the Burrow-Wheeler block sorting text compression algorithm and huffman coding   compress .z Original Unix file compression Utility:starting to fade away into obscurity   gzip .gz The Gnu Project\u0026rsquo;s compression utility; uses Lemperl-ziv coding   zip .zip The unix Version of the PKZIP program for windows    The gzip package is the most popular compression tool in Linux. The gzip package is a creating of the Gnu project in their attempt to create a free version of the original unix compress utility. This package includes these files:\n gzip for compressing files. gzcat for displaying the contend of compressed text files. gunzip for uncompressing files.  These utilities work the same way as the bzip2 utilities.\n[dwm@edwin ~]$ gzip file1 [dwm@edwin ~]$ ls -l fi* -rw-r--r-- 1 dwm wheel 45 May 11 23:41 file1.gz -rw-r--r-- 1 dwm wheel 26 May 11 23:47 file2 The gzip command compresses the file you specify on the command line. You can also specify more than one filename or even use wilcard character to compress multiple files at once.\n[dwm@edwin ~]$ gzip fi* [dwm@edwin ~]$ ls -la fi* -rw-r--r-- 1 dwm wheel 26 May 12 00:48 file1.gz -rw-r--r-- 1 dwm wheel 26 May 12 00:48 file2.gz -rw-r--r-- 1 dwm wheel 26 May 12 00:48 file3.gz The gzip command compresses every file in the directory that matches the wildcard pattern.\nArchiving data Although the zip command works great for compressing and archiving data into a single file, it\u0026rsquo;s not the standard utility used in the unix and linux worlds. By far the most popular archiving tool used in unix and Linux is the tar command.\nThe tar command war originally used to write files to a tape device for archiving. It can also write the outputs to a file, which has become a popular way to archive data in linux.\nThe following is the format of the tar command:\n tar function [option] object1 object2..  Some options for the command includes:\n   Options Description     -C dir Changes to the specified directory   -f file Outputs results to file (or device) file   -j Redirects outputs to the bzip2 command for compression   -p Preserves all file permission   -v List files as they are processed   -z Redirects the outputs to the gzip command for compression    The options are usually combined to creade the following scenarios. First, you want to create an archive file using this command:\ntar -cvf test.tar test/ test3/ The above command creates an archive file called test.tar containing the contents or both the test directory and the test2 directory.\ntar -tf test.tar list (but doesn\u0026rsquo;t extract) the content of the tar file test.tar. Finaly, this command:\ntar -xvf test.tar extract the content of the tar file test.tar.If the tar was created from a directory, the entire directory structure is re-created starting at the current directory. This is a common method for distributing source code files for open source application in the linux world.\nUnderstanding the shell Now that you know a few shell basics its time to explore the actual shell process. To understand the shell, you need to understand a few cli basics.\nA shell is not just a cli. It a complicated interactive running program. Entering commands and using the shell to run scripts can raise some interesting and confusing issues. Understanging the shell process and its relationships help you resolve these issues or avoid them altogether.\nExploring the Shell Types The bash shell program resides in the /bin directory. A long listing reveals /bin/bash is an executable program.\n[dwm@edwin ~]$ ls -lF /bin/bash -rwxr-xr-x 1 root root 903504 Feb 17 14:31 /bin/bash*  Also, the zsh installed used for this distribution.\n[dwm@edwin ~]$ ls -lF /bin/zsh -rwxr-xr-x 2 root root 869608 Feb 16 20:55 /bin/zsh*  The default interactive shell starts whenever a user logs into a virtual console terminal or start a terminal emulator in the GNU. The default system shell is used for system shell script such as those needed at startup.\nOn some distribution, the default system shell is different that the default interactive shell, such as the ubuntu distribution.\n[dwm@edwin ~]$ cat /etc/passwd root❌0:0::/root:/bin/bash eduuh❌1003:998::/home/eduuh:/bin/zsh  Note that the user, eduuh has his default interactive shell set to /bin/zsh, the zsh shell. But the default system shell is set to bash.\nYou are not forced to stick with your default interactive shell. You can start any shell available on your distribution, simply by typing its filename. For example, to start the bash shell.\n [dwm@edwin ~]$ bash  It doest seem like much happened. However the bash shell program started. To exit the bash shell use the exit command\nExploring Parent and child shell Relationships. The default interactive shell started when a usert logs into a virtual console terminal or starts the terminal emulator in the GUI is a parent shell. A parent shell process provides a cli prompt and waits for commands to be entered.\nWhen the /bin/bash command or the equivalent bash command is entered at the cli prompt, a new shell program is created. This is a child shell. A child shell also has a cli prompt and waits for command to be entered.\nA command to bring all this to clarity.\n [dwm@edwin ~]$ ps -f UID PID PPID C STIME TTY TIME CMD dwm 14077 4942 0 11:37 pts/6 00:00:00 -zsh dwm 20887 14077 0 12:05 pts/6 00:00:00 ps -f [dwm@edwin ~]$ bash [dwm@edwin ~]$ ps -f UID PID PPID C STIME TTY TIME CMD dwm 14077 4942 0 11:37 pts/6 00:00:00 -zsh dwm 20933 14077 1 12:06 pts/6 00:00:00 bash dwm 20950 20933 0 12:06 pts/6 00:00:00 ps -f  The first use of ps -f shows two processes. One process has a process ID of 14077. After running the bash shell .\nThe second use of ps -f shows the bash shell is running with a child process ID of 20933 with the PPID of 14077.\nPPID stands for Parend Process ID  When a child shell process is spawned, only some of the parent\u0026rsquo;s environment is copied to the child shell envirionment.\nA child shell is also called a subshell. A subshell can be created from a parent shell and a subshell can be created from another subshell.\n [dwm@edwin ~]$ ps -f UID PID PPID C STIME TTY TIME CMD dwm 14077 4942 0 11:37 pts/6 00:00:00 -zsh dwm 23230 14077 0 12:16 pts/6 00:00:00 ps -f [dwm@edwin ~]$ bash [dwm@edwin ~]$ bash [dwm@edwin ~]$ bash [dwm@edwin ~]$ bash [dwm@edwin ~]$ ps --forest PID TTY TIME CMD 14077 pts/6 00:00:00 zsh 23242 pts/6 00:00:00 \\_ bash 23250 pts/6 00:00:00 \\_ bash 23262 pts/6 00:00:00 \\_ bash 23275 pts/6 00:00:00 \\_ bash 23307 pts/6 00:00:00 \\_ ps  Not only does this exit command allow you to leave child subshell, but you can also log out of your current virtual console terminal or terminal emulator software as well. Just type exit in the parent shell and you gracefully exit the cli.\nLooking at process lists You can designate a list of commands to be run one after another. This is done by entering a command list using a semicolon (;) between commands.\n[dwm@edwin ~]$ pwd ; ls ; cd /etc ; pwd ; cd ; pwd ; ls  The commands all executed one after another with no problems. However, this is not a process list. For a command list to be considered a process list, the command must be encased.\n[dwm@edwin ~]$ (pwd; ls;cd /etc ; pwd ; cd ; pwd ; ls)  The parenthesis does not appear to be a big different, they do cause a very different effect. The very different effect. Adding parentheses and turning the command list into a process list created a subshell to execute the commands.\n [dwm@edwin ~]$ pwd ; ls ; cd /etc ; pwd ; cd ; pwd ; ls ; echo $BASH_SUBSHELL /home/dwm d hd node_modules README.md visual-studio-code-bin Documents larb package.json Templates visual-studio-code-bin.tar.gz [...] 0  At the very end of the command\u0026rsquo;s outputs, you can see the number zero (0) is displayed. The results are different using a process list.\n Note the environment variable (BASH_SUBSHELL) is updated when a child subshell is created in the system.  To indicate if a subshell was spawned, a command using an environment variable is needed here.\n [dwm@edwin ~]$ (pwd ; ls; cd /etc ; pwd; cd ; ls ; echo $BASH_SUBSHELL) /home/dwm d hd node_modules README.md visual-studio-code-bin Documents larb package.json Templates visual-studio-code-bin.tar.gz Downloads LICENSE package-lock.json test w` [..] 1  In this case, the number one(1) displayed at the output\u0026rsquo;s end.This indicates a subsheell was indeed created and used for executing these commands. You can even create a grandchild subshell by embedding parentheses within a process list:\n [dwm@edwin ~]$ (pwd; echo $BASH_SUBSHELL) /home/dwm 1 [dwm@edwin ~]$ (pwd; (echo $BASH_SUBSHELL)) /home/dwm 2  Creatively using subshells One productive subshell method in the interactive sell uses background mode.\nInvestigating background mode Running a command in backgrount mode allows the command to be processed and frees up your cli for other uses. A classic command to demostrate background mode is the sleep command.\nThe sleep command acceptsas a parameter the number of seconds you want the process to wait(sleep). This command is often used to introduce pauses in shell scripts. The command sleep 10.\nTo put a command into background mode, the \u0026amp; character is tacked onto its end. Putting the sleep command into background mode allows a little investigation with the ps command.\n [dwm@edwin ~]$ sleep 10\u0026amp; [1] 39047  when a program is put into background , two information were displayed before the shell CLI prompt was returned. The first information item is the background job\u0026rsquo;s number (1) displayeg in brackedt. The second item is the background job\u0026rsquo;s process ID 39047.\nThe ps command was used to display the various processes. Notice that the sleep command is listed.\nIn addition to the ps command, you can use the jobs command to display background job information. The jobs command displays any use\u0026rsquo;r process (jobs)a currently running in background mode.\nThe jobs command shows the job number (1) in brackets. It also displys the job\u0026rsquo;s current status(running) as well.\n [dwm@edwin ~]$ sleep 3000\u0026amp; [1] 40318 [dwm@edwin ~]$ jobs [1]+ Running sleep 3000 \u0026amp; [dwm@edwin ~]$ jobs -l [1]+ 40318 Running sleep 3000 \u0026amp;  when the backgrund job is finished, its completion status is displayed.\nBackground mode is very handy. And it Provides a method for creating useful subshells at the CLI.\nPutting process lists in the background  [dwm@edwin ~]$ (sleep 2 ; echo $BASH_SUBSHELL ; sleep 2) 1  A two second pause occurs, the number one (1) is displayed indicating a single subshell level (child subshell level), and then another two-second pause occurs before the prompt returns.Putting the same process list in background mode can caouse a slightly different effect with the commang output.\nPutting the process list into the background mode causes a job number and process ID to appear.\n [dwm@edwin ~]$ (sleep 2 ; echo $BASH_SUBSHELL ; sleep 2)\u0026amp; [2] 42121 [dwm@edwin ~]$ 1 [2]+ Done ( sleep 2; echo $BASH_SUBSHELL; sleep 2 )  Using a process list in background mode in one creative method for using subshells at the cli. You can do large amount of processing withing a subshell and not have your termnal tied up withe the subshell\u0026rsquo;s I/O.\nPutting a process list in background mode in not the only wat to used subshells creatively at the CLI. CO-processing in another method.\nLooking at co-processing Co-Processing does things at thes same time. It spawns a subshell in background mode and executes a command witing the subshell:\nYou can be really clever and combine co-processing withe process lists creating nested subshells. Just type your process list and put the command coproc in front of it.\n[dwm@edwin ~]$ coproc (sleep 10; sleep 2) [1] 45198 [dwm@edwin ~]$ jobs [1] + running ( sleep 10; sleep 2; ) [dwm@edwin ~]$ ps --for [1] + done ( sleep 10; sleep 2; ) [dwm@edwin ~]$ ps --forest PID TTY TIME CMD 14077 pts/6 00:00:02 zsh 45244 pts/6 00:00:00 \\_ ps 40318 pts/6 00:00:00 sleep   Note spawning a subshell can be expensive and slow. Creating nested subshells is even more so!  ","description":"","id":4,"section":"posts","tags":["productivity","bash"],"title":"Learn CLI and Bash Scripting","uri":"https://eduuh.github.io/posts/bashscripting/"},{"content":"Advanced Git WorkShop Hello am Edd and I will be taking you through this workshop.By the end of this workshop, if you follow along you have a completely different understanding of Git and how you work with it.\nHow we will go along I will start will a short demo on the command line to introduce the new material.\nAfter a bit we will have some exercise for you to practise what we were going through. After you finish the exercises we are\nthen going to it together, to make sure you understand.\nRequirements  Command Line that support unix style commands git version \u0026gt; 2.0 (check with git \u0026ndash;version) github.com account This Repository 👇  1  git clone git@github.com:eduuh/Advanced-GitWorkshop.git   Are we all good at these requirements. Okay Let get into it.\nI know when we learn git we memorize 6 command the rest of git is usually a black box that we don\u0026rsquo;t explore. We reach at a point where we really on the GUI tool available for working with git. I.e visual studio code.Today we are going to go a lot deeper to git away from this basic commands and explore git further.\nMy \u0026ldquo;assumption\u0026rdquo; is you are familiar with this commands. Don\u0026rsquo;t worry if you are a beginner you will get into pace soon.\n   Command Action     git clone clone a remote repository : github, gitlab , azure repos   git push Push local repository to remote service   git fetch Pull changes to a local repository   git pull -f git fetch + git merge (used flags right)   git init Initialize a repository locally   git add \u0026amp; git commit Add changes to a local repository.    If you are not famialiar with the above commands. Please bare with me, this are usually common concept that we can\u0026rsquo;t do without them. When we come across them i will explain to you what they do.\nI felt this way untill i decided its time to level up a little bit and come out of my confort zone. Using GUI tools. In my case visual studio code.\nDo you feel this way?\nIts a sad place to be. Are you exited to not do this anymore!?\nI will try to get you out of this showing you how to use git the right way.\nBefore you delete you could decide to look up some manual page for git online and this is what you might get.\nWAT?\nThe SYNOPSIS WTH does it mean??\n git refers to its self as A stupid content tracker funny\nBut this depends on how your use case and mood.\n  Notes  People use git for different use cases. You should try to use the idea from this workshop and incoporate them to your workflows.\n   I have divided this workshop into sections , and after each sections. Am going to give an exercise which you will attempt. And then we are going to them together.\nLets focus more on doing and understanding the theory. This is what i mean. Instead of writing down the notes focus on trying out the commands. You have all these notes with you.\nGit is a tool to helps you,but not work against you.\nGit concepts  Untracked Files  New files that git have not requested to track previously.\n Working Area  Worked that is tracked by git that has been modified but have not yet been commited.\n Staging Area  Modified files that have been marked to go the next commit.\nThis are terms that will appear mostly in this workshop.\nHow is information stored. At its core, git is like a key value store.\n Value = Data (our files) Key =\u0026gt; Sha1 Key   Key  Its a crytographic hash function. Given a piece of data , it produces a 40 - digit hexadecimal numbers. You will see this in a bit.\nThis value should always be the same if the given Input it the same.\n Value  Git store the compressed data in a blob , along with the metadata in a header. Holds the identifier of the, size of the content and the content itself.\nNote: The content is compressed and when you cat into it you will get a whole lot of nothings.\nUnder the Hood - Lets create a git hash object. Git will take our content and use it to generate the hash key. For now we could supply some content to git using echo command.\nIf you run the command. Here we are piping the output of the echo command to the git hash function requesting to use the stdin\nThe hash function returns the a hash which should be the same for all of us.your can try this\n1 2  echo hello | git hash-object --stdin # ce013625030ba8dba906f756967f9e9ca394464a   We already know some tools that are used to generate sha1 keys. For my system I believe its openssl\nlets generate Sha1 using openssl\n1 2  echo hello | openssl sha1 # (stdin)= f572d396fae9206628714fb2ce00f72e94f2258f   Thes hash are different. This is because git hash function **prepends thes string \u0026ldquo;blob\u0026rdquo; followed by the file size and a null to the file\u0026rsquo;s content before hashing.\nThis is how git calculates the sha1 for the file (in git term a blob)\nGit calculate the files metadata + content , not just the content.\n1  # sha1(\u0026#34;blob\u0026#34; + filesize + \u0026#34;\\0\u0026#34; + data) # not \\0 is a null byte   When you run the hash function on the same content you will always get the same result.\nLets initialize a repository 1 2  git init # Initialized empty Git repository in $HOME/username/dir/.git/   The initialized repository is store at .git directory.\nWhey you delete this folder in a repository you actually blow up the repository, but you retains the files that were availble in the working area.\n question: where are blob stored?  We are going to rerun the command that ask git to generate a sha1 key for the content but this time we pass a option , -w that indicates we want to write the object to the git repo.\n1 2  echo hello | git hash-object -w --stdin ce013625030ba8dba906f756967f9e9ca394464a   Take a note at the hash generated at this point. and lets access how it is saved in the git folder.\n lets do some clean up first\n Remove the hooks directory in the repository, so that it does not get into our way.\n1  rm -rf .git/hooks # r =\u0026gt; recusive f =\u0026gt; folders   Now you can tree into the .git folder to pic at all the content.\nNote if you have alot of files in your working directory u are going to have a longer structure. ***The output look something like.\n1  tree .git/   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  .git/ ├── branches ├── config ├── description ├── HEAD ├── index ├── info │ └── exclude ├── logs │ ├── HEAD │ └── refs │ ├── heads │ │ └── master │ └── remotes │ └── origin │ └── HEAD ├── objects │ ├── 07 │ │ └── 9830d5ae8de34a3faf6bd8ff8b680684948bec │ ├── ce │ │ └── 013625030ba8dba906f756967f9e9ca394464a   Our initial sha1 file was ce013625030ba8dba906f756967f9e9ca394464a.\nwhat do you notice?  Our blob is stored in the object folder. You can\u0026rsquo;t see that yet but you will.  2 Inside a subfolder which picks the first two char of the blob (ce)\n3.The blob object as the rest of the char (013625030ba8dba906f756967f9e9ca394464a)\nDo this Step by step  Create an empty directory and initialize a new repository  Copy the command as it will work.\n mkdir makes a directory. cd move into the directory git init initiaze the repository  1  mkdir test ; cd test ; git init   One you initialize a repository a .git folder is created where all git information is stored.\nThe .git folder have a few empty directories. If you have never checked the .git directory lets start now.\nCheck the folder structure of the .git directory.  1  ls -la .git   drwxr-xr-x 7 edd eduuh 4096 Feb 15 19:45 ./ drwxr-xr-x 3 edd eduuh 4096 Feb 15 19:45 ../ drwxr-xr-x 2 edd eduuh 4096 Feb 15 19:45 branches/ -rw-r--r-- 1 edd eduuh 92 Feb 15 19:45 config -rw-r--r-- 1 edd eduuh 73 Feb 15 19:45 description -rw-r--r-- 1 edd eduuh 23 Feb 15 19:45 HEAD drwxr-xr-x 2 edd eduuh 4096 Feb 15 19:45 hooks/ drwxr-xr-x 2 edd eduuh 4096 Feb 15 19:45 info/ drwxr-xr-x 4 edd eduuh 4096 Feb 15 19:45 objects/ drwxr-xr-x 4 edd eduuh 4096 Feb 15 19:45 refs/ Remove the .git/hooks folder. you dont need for now  1  rm -rf `.git/hooks`   Look at the folder structure in a graphical way using the tree command.  1  tree .git/   Lets add a file in our repository. Using the echo command you can redirect the output to a file.  1 2 3 4 5 6 7 8  # will write the line ot gitstuff.txt file echo \u0026#39;an awesome guide to git\u0026#39; \u0026gt; gitstuff.txt # you can check the content of the file using cat command cat gitstuff.txt git hash-object -w gitstuff.txt # 24997081c3c51eeac9df4309dbcc9452112a8f1f   You should the same hash code as i get here as long us you use the same content as i did.\nThis time the git hash function command takes a path to a file unlike intially where echo was used to input to the stdin of the function\nSomething i realize with the ls -la command that actually the blob is a file. We can just read from it since it compressed into a c binary file. Lets try fo fun  lets us the find command to look for all files. Since we now know the blob are store in the object we could narrow our search in directory.\n1 2  find .git/object/ --type f # .git/objects/24/997081c3c51eeac9df4309dbcc9452112a8f1f   We\u0026rsquo;ve created our first object! this is a binary file that holds what we just saved.\nNote The object id is choosen based on the content of the object. This is how git stores our object. Let me use the right word here content-addressable filesystem.\nLets try to save the same file again.  1  git hash-object -w gitstuff.txt   Because it the same content, nothing changes we will receive the same sha1 hash key\n Question: How can we see the content of the blob??   When you cat pathtofile you will get a whole lot of nothing.To be more accurate a binary output\nLets try\n1 2 3 4 5 6  # use the find command to get the path find .git/objects -type f # .git/objects/24/997081c3c51eeac9df4309dbcc9452112a8f1f cat .git/objects/24/997081c3c51eeac9df4309dbcc9452112a8f1f # xK��OR02aH�SH,O-��MUH/�LIU(�WH�,���   Git provides a functions to view the content of blobs.cat-file\n -p =\u0026gt; print out pretty print -t =\u0026gt; print out the type  For this command you use the sha1 hash as the arguement.\n1 2 3 4 5  git cat-file -p 24997081 # an awesome guide to git git cat-file -t 24997081 # blob   Useful commands    command detail     kkdir  creates a directory   git init initialize git in the directory   ls -la .git lists the content of the .git directory   find .git/object/ -type -f list all files available in a directory   git hash-object -w  Saves the files to a git object store.   **git cat-file -p  pretty print the content of the object in the git object store.    This takes you to exercise one\nWe need other stuff, right? Our blob is missing information.\n filenames. directory structure.  wheres is this information stored in git?\n Tree  Git stores filename , directory structure here.\na tree contains pointers (using sha1).\n to blobs.\nto other trees.\n and metadata\n type of pointer filename of directory name mode (excutable file, symbolic link,..)  Has anyone ever tried to add empty directories to git?\ngit can\u0026rsquo;t of dont store empty directories.\nIdentical content is only store once.\nOther Optimization - Packfilse and Deltas  Git object are compressed As files change, their content remains mostly similar. Git optimize for this by compressing these files together, into a Packfiles. The packfile stores the object and deltas , of the differences between one version of the file\nand the next. Packfiles are generated when:\nYou have too many objects , during gc, or during a push to remote.  You kind start to understand what happens during a git push where you see that message.\n compressing deltas\n Commit OBJECT A commit is a code snapshot.\nA commit points to\n A tree  and contains metadata:\n author and committer\ndate\nmessage\nparend commit (one or more)\n The sha1 of the commit is the hash of all this information.\nPractically   lets perfom a git status on the repo we created.\n $ git status On branch master No commits yet Untracked files: (use \u0026quot;git add \u0026lt;file\u0026gt;...\u0026quot; to include in what will be committed) learn-copy.txt learn.txt $ git add . # add all the files to the staging area $ git commit -m \u0026quot;finished working on gitworkshop\u0026quot; [master (root-commit) 3cb087a] finished working on git workshop 2 files changed, 4 insertions(+) create mode 100644 learn-copy.txt create mode 100644 learn.txt $ tree .git/objects .git/objects/ ├── 1e │ └── 234f233918794921501400511445247278c890 ├── 3c │ └── b087a3be11296eee71a0527dfe77a139688d68    Note after a commit, git provide the first character of the sha1 hash identifier for the commit. for this case its 3cb087a .\nWhen you look into the .git/objects directory using the tree\ncommand. you notice that the commit create a folder structure and has an object in it.\nGit-file -T (Type) and -P (PRINT) THE CONTENT  $ git cat-file -t 3cb087a commit $ git cat-file -p 3cb087a tree 1e234f233918794921501400511445247278c890 author eduuh \u0026lt;edwinkamaumuraya0@outlook.com\u0026gt; 1581803358 +0300 committer eduuh \u0026lt;edwinkamaumuraya0@outlook.com\u0026gt; 1581803358 +0300 finished working on git workshop  Take away from this  We can\u0026rsquo;t change the Commits!\n   if you change any data about the commit, the\ncommit will have a new SHA1 hash.\n  even ef the files dont change the date will .\n  This give use the sense of high security in git and you will always know that you commit history will always maintaint its integrity. No one in your team can mess with your commit message without becoming obvious.\nIt also secures agaish corruption. If files on the disk change, the repository will notify that the content do not match.\nREFERENCES - POINTERS TO COMMITS  tags\nbranch\nHEAD -\u0026gt; a pointer to the current commit.\n Why are checkout in git really fast? This is because, it not pulling in other data. but its just changing the pointers.\nThree areas where code lives  Working area Staging area Repository  Working area The files in your working area that are also not in the staging area are not handled by git.\nAlso called untracked files\nThe staging area  What files are going to be part of your next commit. the staging area is how git knows what will change between the current commit and the next commit.  Tip: a clean staging area isn\u0026rsquo;t empty!\nconsider the baseline staging are as being an exact copy of the latest commit.\nThe Repository The files git knows about !\nContans all of your commit.\nthe repository is stored in the .git folder.\nMoving files in \u0026amp; of the staging area Add a file to the next commit.\ngit add \u0026lt;filename\u0026gt;  delete a file in the next commit\ngit rm \u0026lt;file\u0026gt;  rename a file in the next commit:\ngit mv \u0026lt;file\u0026gt;  Git ADD -p  One of my favorite tools  allows you to stage commits in hunks\nInteractively\nIt\u0026rsquo;s especially useful if you\u0026rsquo;ve done too much work for one commit.\nUnstage files fron the staging area Not removing the files\nYou\u0026rsquo;re replacing them with a copy that\u0026rsquo;s currently in the repository.\nGit STASH This is usually a way to save uncommited work.\nThe stash is safe from destructive operations.\nchanging between branches which requires you to have commited all your changes.  Git stash Basic use Stash changes\ngit stash  list changes\ngit stash list  show content\ngit stash show stash@{0}  apply the last stash\ngit stash apply  apply specific stash\ngit stash apply stash@{0}  by default git stash stash tracked files that are either in the repository or staging area.\nAdvanced STASHING - Operations Let give a scenario. You have added a new file in the repository and you dont want to git add it yet, but you need\nto switch to a different branch. Advanced stashing comes in\nhandy. If you switch to a different branch with untracted files\nin your working area you could accidentally commit this file.\nKeeping untracted file it a stash git stash --include-untracked  you this with cautions git stash -all  this could add even ingored files.\nName stashes for easy reference git stash save \u0026quot;WIP: making progress on foo\u0026quot;  start a new brance from a stash git stash branch \u0026lt;optional branch name\u0026gt;  Grab a single files from a stash git checkout \u0026lt;stash name\u0026gt; --\u0026lt;filename\u0026gt;  Remove the last stash and applying changes git stash pop  tip : doest remove if there are a merge conflict\nRemove the last stash git stash drop stash@{0}  Remove all stashes git stash clear  Exercise ","description":"Guide to git expert","id":6,"section":"workshops","tags":["version control","Productivity","git","github"],"title":"Advanced Git WorkShop","uri":"https://eduuh.github.io/workshops/git/advancedgit/"},{"content":"Sample images from Pixabay\n","description":"photo gallery","id":8,"section":"gallery","tags":null,"title":"Photo","uri":"https://eduuh.github.io/gallery/photo/"},{"content":"Introduction A blog where i i will be writing on the following Technologies.\n React React Native Dotnet core Linux Terminal  Maintainer A Self Taught Developer : Edwin Muraya Currenty A BSC Geomatic and Geospartial Information System Student at Dedan Kimathi University\n","description":"","id":9,"section":"","tags":null,"title":"About Edds Blog","uri":"https://eduuh.github.io/about/"}]